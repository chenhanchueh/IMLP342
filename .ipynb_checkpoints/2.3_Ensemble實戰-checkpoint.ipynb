{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "2.3_Ensemble實戰-checkpoint.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenhanchueh/IMLP342/blob/main/.ipynb_checkpoints/2.3_Ensemble%E5%AF%A6%E6%88%B0-checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3129ab3d"
      },
      "source": [
        "# Ensemble/Voting Classification in Python with Scikit-Learn\n",
        "ref：https://www.kaggle.com/c/titanic/submit"
      ],
      "id": "3129ab3d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6b020b8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier"
      ],
      "id": "c6b020b8",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3X1AnL64MLh",
        "outputId": "64aa0c14-360b-468a-982b-716c9dda8f51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "O3X1AnL64MLh",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7163b994",
        "outputId": "550ba8f8-47c5-4ab2-a6d5-5303e0c2d680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_data = pd.read_csv(\"/train.csv\")\n",
        "testing_data = pd.read_csv(\"/test.csv\")\n",
        "\n",
        "def get_nulls(training, testing):\n",
        "    print(\"Training Data:\")\n",
        "    print(pd.isnull(training).sum())\n",
        "    print(\"Testing Data:\")\n",
        "    print(pd.isnull(testing).sum())\n",
        "\n",
        "get_nulls(training_data, testing_data)"
      ],
      "id": "7163b994",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "Testing Data:\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffd6109f",
        "outputId": "e5cbdf34-be3b-4d6d-f056-cad921ee6936",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Drop the cabin column, as there are too many missing values\n",
        "# Drop the ticket numbers too, as there are too many categories\n",
        "# Drop names as they won't really help predict survivors\n",
        "# training_data.drop(labels= [\"Cabin\", \"Ticket\", \"Name\"], axis= 1, inplace= True)\n",
        "# testing_data.drop(labels= [\"Cabin\", \"Ticket\", \"Name\"], axis= 1, inplace= True)\n",
        "\n",
        "# Taking the mean/average value would be impacted by the skew\n",
        "# so we should use the median value to impute missing values\n",
        "training_data[\"Age\"].fillna(training_data[\"Age\"].median(),inplace=True)\n",
        "testing_data[\"Age\"].fillna(training_data[\"Age\"].median(),inplace=True)\n",
        "training_data[\"Embarked\"].fillna(\"S\",inplace=True)\n",
        "testing_data[\"Fare\"].fillna(training_data[\"Fare\"].median(),inplace=True)\n",
        "\n",
        "get_nulls(training_data, testing_data)"
      ],
      "id": "ffd6109f",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "Testing Data:\n",
            "PassengerId    0\n",
            "Pclass         0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19e4f59b"
      },
      "source": [
        "# Fit the encoder on the data (Feature: Sex)\n",
        "encoder_1 = LabelEncoder()\n",
        "encoder_1.fit(training_data[\"Sex\"])\n",
        "\n",
        "# Transform and replace training data\n",
        "training_sex_encoded = encoder_1.transform(training_data[\"Sex\"])\n",
        "training_data[\"Sex\"] = training_sex_encoded\n",
        "test_sex_encoded = encoder_1.transform(testing_data[\"Sex\"])\n",
        "testing_data[\"Sex\"] = test_sex_encoded\n",
        "\n",
        "# Fit the encoder on the data (Feature: Embarked)\n",
        "encoder_2 = LabelEncoder()\n",
        "encoder_2.fit(training_data[\"Embarked\"])\n",
        "\n",
        "training_embarked_encoded = encoder_2.transform(training_data[\"Embarked\"])\n",
        "training_data[\"Embarked\"] = training_embarked_encoded\n",
        "test_embarked_encoded = encoder_2.transform(testing_data[\"Embarked\"])\n",
        "testing_data[\"Embarked\"] = test_embarked_encoded\n",
        "\n",
        "# Any value we want to reshape needs be turned into array first\n",
        "ages_train = np.array(training_data[\"Age\"]).reshape(-1, 1)\n",
        "ages_test = np.array(testing_data[\"Age\"]).reshape(-1, 1)\n",
        "fare_train = np.array(training_data[\"Fare\"]).reshape(-1, 1)\n",
        "fare_test = np.array(testing_data[\"Fare\"]).reshape(-1, 1)\n",
        "\n",
        "# Scaler takes arrays\n",
        "scaler = StandardScaler()\n",
        "\n",
        "training_data[\"Age\"] = scaler.fit_transform(ages_train)\n",
        "testing_data[\"Age\"] = scaler.fit_transform(ages_test)\n",
        "training_data[\"Fare\"] = scaler.fit_transform(fare_train)\n",
        "testing_data[\"Fare\"] = scaler.fit_transform(fare_test)"
      ],
      "id": "19e4f59b",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65bd0090",
        "outputId": "0b2314a3-3fa3-4e73-cf6a-0968f9a1b741",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now to select our training/testing data\n",
        "X_features = training_data.drop(labels=['PassengerId', 'Survived'], axis=1)\n",
        "y_labels = training_data['Survived']\n",
        "\n",
        "print(X_features.head(5))\n",
        "print(y_labels.head(5))\n",
        "\n",
        "# Make the train/test data from validation\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_features, y_labels, test_size=0.1,random_state=12)"
      ],
      "id": "65bd0090",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
            "0       3    1 -0.565736      1      0 -0.502445         2\n",
            "1       1    0  0.663861      1      0  0.786845         0\n",
            "2       3    0 -0.258337      0      0 -0.488854         2\n",
            "3       1    0  0.433312      1      0  0.420730         2\n",
            "4       3    1  0.433312      0      0 -0.486337         2\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Survived, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5652bc34"
      },
      "source": [
        "## Simple Averaging Approach"
      ],
      "id": "5652bc34"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cd452cc",
        "outputId": "faf35360-fa19-456b-932f-cf48e8031675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "LogReg_clf = LogisticRegression()\n",
        "DTree_clf = DecisionTreeClassifier()\n",
        "SVC_clf = SVC()\n",
        "\n",
        "LogReg_clf.fit(X_train, y_train)\n",
        "DTree_clf.fit(X_train, y_train)\n",
        "SVC_clf.fit(X_train, y_train)\n",
        "\n",
        "LogReg_pred = LogReg_clf.predict(X_val)\n",
        "DTree_pred = DTree_clf.predict(X_val)\n",
        "SVC_pred = SVC_clf.predict(X_val)\n",
        "\n",
        "averaged_preds = (LogReg_pred + DTree_pred + SVC_pred)//3\n",
        "acc = accuracy_score(y_val, averaged_preds)\n",
        "print(acc)"
      ],
      "id": "9cd452cc",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82d32100"
      },
      "source": [
        "## Bagging Classification Example"
      ],
      "id": "82d32100"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ac47a5",
        "outputId": "cd9acf01-ee92-4dd5-dc34-1f95f2b473a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "logreg_bagging_model = BaggingClassifier(base_estimator= LogReg_clf, n_estimators= 50, random_state= 12)\n",
        "dtree_bagging_model = BaggingClassifier(base_estimator= DTree_clf, n_estimators= 50, random_state= 12)\n",
        "random_forest = RandomForestClassifier(n_estimators= 100, random_state= 12)\n",
        "extra_trees = ExtraTreesClassifier(n_estimators= 100, random_state= 12)\n",
        "\n",
        "def bagging_ensemble(model):\n",
        "    k_folds = KFold(n_splits=20, random_state=12,shuffle=True)\n",
        "    results = cross_val_score(model, X_train, y_train, cv=k_folds)\n",
        "    print(results.mean())\n",
        "\n",
        "bagging_ensemble(logreg_bagging_model)\n",
        "bagging_ensemble(dtree_bagging_model)\n",
        "bagging_ensemble(random_forest)\n",
        "bagging_ensemble(extra_trees)"
      ],
      "id": "62ac47a5",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7927134146341464\n",
            "0.8138719512195122\n",
            "0.8113719512195123\n",
            "0.7963719512195122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09094ea7"
      },
      "source": [
        "## Boosting Classification Example"
      ],
      "id": "09094ea7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a6d48bb",
        "outputId": "5ccad3bf-70d8-44b5-da5e-38a227f9cb88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "k_folds = KFold(n_splits=20, random_state=12,shuffle=True)\n",
        "num_estimators = [20, 40, 60, 80, 100]\n",
        "\n",
        "for i in num_estimators:\n",
        "    ada_boost = AdaBoostClassifier(n_estimators= i, random_state= 12)\n",
        "    results = cross_val_score(ada_boost, X_train, y_train, cv= k_folds)\n",
        "    print(\"Results for {} estimators:\".format(i))\n",
        "    print(results.mean())"
      ],
      "id": "0a6d48bb",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for 20 estimators:\n",
            "0.8052134146341464\n",
            "Results for 40 estimators:\n",
            "0.8176524390243903\n",
            "Results for 60 estimators:\n",
            "0.8164329268292683\n",
            "Results for 80 estimators:\n",
            "0.8151524390243902\n",
            "Results for 100 estimators:\n",
            "0.8101524390243903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8290c946"
      },
      "source": [
        "## voting\\Stacking Classification Example"
      ],
      "id": "8290c946"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "161a4960",
        "outputId": "3e1b7bea-848e-46ff-ec4c-9ab05bc6e82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "voting_clf = VotingClassifier(estimators=[('SVC', SVC_clf), ('DTree', DTree_clf), ('LogReg', LogReg_clf)], voting='hard')\n",
        "voting_clf.fit(X_train, y_train)\n",
        "preds = voting_clf.predict(X_val)\n",
        "acc = accuracy_score(y_val, preds)\n",
        "l_loss = log_loss(y_val, preds)\n",
        "f1 = f1_score(y_val, preds)\n",
        "\n",
        "print(\"Accuracy is: \" + str(acc))\n",
        "print(\"Log Loss is: \" + str(l_loss))\n",
        "print(\"F1 Score is: \" + str(f1))"
      ],
      "id": "161a4960",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.8222222222222222\n",
            "Log Loss is: 6.140280221146135\n",
            "F1 Score is: 0.7575757575757576\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}